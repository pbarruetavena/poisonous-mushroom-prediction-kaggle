{"cells":[{"cell_type":"markdown","source":["**Ajuste de Hiperparametros usando XGBooster**"],"metadata":{"id":"tJ-0QqD9kO4l"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2293016,"status":"ok","timestamp":1725818909562,"user":{"displayName":"Matheus Amaral de Assis•","userId":"04611588066147145920"},"user_tz":180},"id":"AFh1DlCahl58","outputId":"0129b36e-0366-4dd1-9382-4716e3af3fb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/MyDrive/TrabalhoTEI\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-09-08 17:30:53,641] A new study created in memory with name: no-name-c18b6af8-bc13-4fe6-843b-65b651de87f9\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:31:01] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:31:43,622] Trial 0 finished with value: 0.9836063756022954 and parameters: {'max_depth': 9, 'subsample': 0.9543988826106495, 'colsample_bytree': 0.934064691238299}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:31:50] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:32:32,941] Trial 1 finished with value: 0.9835743160642563 and parameters: {'max_depth': 9, 'subsample': 0.8844483649335647, 'colsample_bytree': 0.7688215271075949}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:32:40] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:33:11,081] Trial 2 finished with value: 0.982525377021612 and parameters: {'max_depth': 6, 'subsample': 0.9460124988462926, 'colsample_bytree': 0.7469459966472124}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:33:17] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:33:43,999] Trial 3 finished with value: 0.9727897384166998 and parameters: {'max_depth': 4, 'subsample': 0.9743229129582047, 'colsample_bytree': 0.7453558140990376}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:33:50] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:34:13,988] Trial 4 finished with value: 0.9729761505741911 and parameters: {'max_depth': 4, 'subsample': 0.8586088509561268, 'colsample_bytree': 0.7924170384010154}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:34:20] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:34:58,382] Trial 5 finished with value: 0.9834228557941638 and parameters: {'max_depth': 8, 'subsample': 0.9879124109579287, 'colsample_bytree': 0.775095537090658}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:35:05] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:35:28,001] Trial 6 finished with value: 0.9730726949147098 and parameters: {'max_depth': 4, 'subsample': 0.8646911563090646, 'colsample_bytree': 0.8359982325440952}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:35:36] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:36:13,404] Trial 7 finished with value: 0.9834419067667485 and parameters: {'max_depth': 8, 'subsample': 0.8049680549229686, 'colsample_bytree': 0.9149119393925346}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:36:21] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:36:54,421] Trial 8 finished with value: 0.9822179082399356 and parameters: {'max_depth': 6, 'subsample': 0.7212328865394683, 'colsample_bytree': 0.9143093765454746}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:37:00] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:37:35,481] Trial 9 finished with value: 0.9829996931622497 and parameters: {'max_depth': 7, 'subsample': 0.9268935556285748, 'colsample_bytree': 0.9668425831185059}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:37:41] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:38:23,576] Trial 10 finished with value: 0.9835354365363544 and parameters: {'max_depth': 9, 'subsample': 0.790400915449643, 'colsample_bytree': 0.9837312488550171}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:38:30] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:39:10,261] Trial 11 finished with value: 0.9835902261102744 and parameters: {'max_depth': 9, 'subsample': 0.899378651241594, 'colsample_bytree': 0.7032664486684439}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:39:17] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:40:05,651] Trial 12 finished with value: 0.9834545179639672 and parameters: {'max_depth': 9, 'subsample': 0.9111702046443139, 'colsample_bytree': 0.8936816023699452}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:40:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:40:48,553] Trial 13 finished with value: 0.9830481493244945 and parameters: {'max_depth': 7, 'subsample': 0.9482486100864757, 'colsample_bytree': 0.7113803523448547}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:40:55] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:41:33,132] Trial 14 finished with value: 0.98336434977985 and parameters: {'max_depth': 8, 'subsample': 0.8282328015492286, 'colsample_bytree': 0.8416343041388226}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:41:40] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:42:14,279] Trial 15 finished with value: 0.9828570539899668 and parameters: {'max_depth': 7, 'subsample': 0.8996541333012747, 'colsample_bytree': 0.8715516500512475}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:42:20] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:42:48,970] Trial 16 finished with value: 0.980759023757904 and parameters: {'max_depth': 5, 'subsample': 0.9967283939233377, 'colsample_bytree': 0.9563889423260493}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:42:55] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:43:36,897] Trial 17 finished with value: 0.9835546372923224 and parameters: {'max_depth': 9, 'subsample': 0.7435559402060322, 'colsample_bytree': 0.8114901215642379}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:43:44] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:44:02,674] Trial 18 finished with value: 0.9517160865024681 and parameters: {'max_depth': 3, 'subsample': 0.9515877641451186, 'colsample_bytree': 0.7027896633608992}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:44:10] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:44:46,101] Trial 19 finished with value: 0.9834322772307319 and parameters: {'max_depth': 8, 'subsample': 0.8818705821175277, 'colsample_bytree': 0.9395326319242666}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:44:53] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:45:26,505] Trial 20 finished with value: 0.9831031030911224 and parameters: {'max_depth': 7, 'subsample': 0.9252578484790452, 'colsample_bytree': 0.9934406873387819}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:45:32] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:46:17,270] Trial 21 finished with value: 0.9834027811374334 and parameters: {'max_depth': 9, 'subsample': 0.8848303980038232, 'colsample_bytree': 0.7392510322210298}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:46:24] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:47:09,105] Trial 22 finished with value: 0.9836002504804526 and parameters: {'max_depth': 9, 'subsample': 0.8359066376927184, 'colsample_bytree': 0.7835745525094384}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:47:17] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:47:55,253] Trial 23 finished with value: 0.9833125695230107 and parameters: {'max_depth': 8, 'subsample': 0.8297595128238351, 'colsample_bytree': 0.808731194111125}. Best is trial 0 with value: 0.9836063756022954.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:48:03] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:48:49,602] Trial 24 finished with value: 0.9836131297223805 and parameters: {'max_depth': 9, 'subsample': 0.7700163438450479, 'colsample_bytree': 0.8660166740337075}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:48:55] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:49:35,474] Trial 25 finished with value: 0.9834617139768373 and parameters: {'max_depth': 8, 'subsample': 0.7650693713427662, 'colsample_bytree': 0.8677704940209364}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:49:43] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:50:23,436] Trial 26 finished with value: 0.9835129703666271 and parameters: {'max_depth': 9, 'subsample': 0.7797899025611519, 'colsample_bytree': 0.8888539158075859}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:50:30] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:51:07,337] Trial 27 finished with value: 0.9835328649587141 and parameters: {'max_depth': 8, 'subsample': 0.8290202098708191, 'colsample_bytree': 0.9259406857447475}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:51:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:51:51,929] Trial 28 finished with value: 0.983193000818445 and parameters: {'max_depth': 7, 'subsample': 0.7538440412083859, 'colsample_bytree': 0.8274455081892268}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:51:58] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:52:29,157] Trial 29 finished with value: 0.9823236239987904 and parameters: {'max_depth': 6, 'subsample': 0.7147706988933026, 'colsample_bytree': 0.77184453189343}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:52:36] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:53:16,924] Trial 30 finished with value: 0.983431918873183 and parameters: {'max_depth': 9, 'subsample': 0.8082297415415288, 'colsample_bytree': 0.856643376986751}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:53:23] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:54:08,887] Trial 31 finished with value: 0.9836129772989903 and parameters: {'max_depth': 9, 'subsample': 0.8778061202045865, 'colsample_bytree': 0.8917892180698802}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:54:17] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:55:15,724] Trial 32 finished with value: 0.9834837659667768 and parameters: {'max_depth': 9, 'subsample': 0.8401816679225914, 'colsample_bytree': 0.8919359548068138}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:55:23] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:56:19,177] Trial 33 finished with value: 0.9834772270703427 and parameters: {'max_depth': 9, 'subsample': 0.9702877625654062, 'colsample_bytree': 0.9370586703560534}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:56:26] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:57:14,793] Trial 34 finished with value: 0.9833061657665977 and parameters: {'max_depth': 8, 'subsample': 0.8693455865298463, 'colsample_bytree': 0.8611013714440102}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:57:21] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:58:04,440] Trial 35 finished with value: 0.983448200051842 and parameters: {'max_depth': 9, 'subsample': 0.8088010282302461, 'colsample_bytree': 0.8984581198417254}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:58:12] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:58:36,405] Trial 36 finished with value: 0.9797808017021473 and parameters: {'max_depth': 5, 'subsample': 0.8543987503772994, 'colsample_bytree': 0.876133612518952}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:58:43] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 17:59:21,670] Trial 37 finished with value: 0.9833808897510627 and parameters: {'max_depth': 8, 'subsample': 0.7324076213401765, 'colsample_bytree': 0.8254391042273556}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:59:28] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:00:08,444] Trial 38 finished with value: 0.983587349494617 and parameters: {'max_depth': 9, 'subsample': 0.9699721745407929, 'colsample_bytree': 0.7969341450570052}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:00:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:00:56,280] Trial 39 finished with value: 0.9832639684394306 and parameters: {'max_depth': 8, 'subsample': 0.7027108139350245, 'colsample_bytree': 0.9559153708341508}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:01:04] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:01:44,464] Trial 40 finished with value: 0.9834054892494549 and parameters: {'max_depth': 9, 'subsample': 0.7866461313975498, 'colsample_bytree': 0.7498752025636932}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:01:51] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:02:32,438] Trial 41 finished with value: 0.9835419310843939 and parameters: {'max_depth': 9, 'subsample': 0.9081127273504921, 'colsample_bytree': 0.7246154976527139}. Best is trial 24 with value: 0.9836131297223805.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:02:38] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:03:19,419] Trial 42 finished with value: 0.9836226323111318 and parameters: {'max_depth': 9, 'subsample': 0.9282256890261701, 'colsample_bytree': 0.9086748111812067}. Best is trial 42 with value: 0.9836226323111318.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:03:26] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:04:05,105] Trial 43 finished with value: 0.9834613244208854 and parameters: {'max_depth': 8, 'subsample': 0.9409881280459964, 'colsample_bytree': 0.9171924730715911}. Best is trial 42 with value: 0.9836226323111318.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:04:12] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:04:51,365] Trial 44 finished with value: 0.9837397566419347 and parameters: {'max_depth': 9, 'subsample': 0.9276592101046933, 'colsample_bytree': 0.9119456082162385}. Best is trial 44 with value: 0.9837397566419347.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:04:58] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:05:38,872] Trial 45 finished with value: 0.9835189840633746 and parameters: {'max_depth': 9, 'subsample': 0.9277538932532501, 'colsample_bytree': 0.904415433399398}. Best is trial 44 with value: 0.9837397566419347.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:05:45] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:06:25,027] Trial 46 finished with value: 0.9834875575036717 and parameters: {'max_depth': 8, 'subsample': 0.9825909235911677, 'colsample_bytree': 0.8791963410449802}. Best is trial 44 with value: 0.9837397566419347.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:06:31] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:07:10,391] Trial 47 finished with value: 0.9825182083969453 and parameters: {'max_depth': 6, 'subsample': 0.8827062972507285, 'colsample_bytree': 0.9320370892962807}. Best is trial 44 with value: 0.9837397566419347.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:07:19] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:08:02,650] Trial 48 finished with value: 0.9833700700515149 and parameters: {'max_depth': 9, 'subsample': 0.9561370778697044, 'colsample_bytree': 0.9142361065749443}. Best is trial 44 with value: 0.9837397566419347.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:08:10] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:08:29,048] Trial 49 finished with value: 0.9438963601729929 and parameters: {'max_depth': 3, 'subsample': 0.934165320024731, 'colsample_bytree': 0.8463367623273583}. Best is trial 44 with value: 0.9837397566419347.\n"]},{"name":"stdout","output_type":"stream","text":["Melhores hiperparâmetros:  {'max_depth': 9, 'subsample': 0.9276592101046933, 'colsample_bytree': 0.9119456082162385}\n","Melhor MCC:  0.9837397566419347\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/TrabalhoTEI\n","\n","import pandas as pd\n","import numpy as np  # Importar numpy para manipulação de arrays\n","import optuna\n","import xgboost as xgb\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Carregar os dados\n","train_df = pd.read_csv('train.csv')\n","test_df = pd.read_csv('test.csv')\n","\n","# Criar LabelEncoders para cada coluna categórica\n","label_encoders = {}\n","\n","# Transformação no conjunto de treino\n","for col in train_df.columns:\n","    if col != 'id':  # Não transformamos a coluna 'id'\n","        le = LabelEncoder()\n","        train_df[col] = le.fit_transform(train_df[col])\n","        label_encoders[col] = le  # Armazenar o encoder para usar no teste\n","\n","# Transformação no conjunto de teste\n","for col in test_df.columns:\n","    if col != 'id':  # Não transformamos a coluna 'id'\n","        le = label_encoders.get(col)  # Recuperar o encoder correspondente\n","        if le is not None:\n","            # Identificar e tratar rótulos desconhecidos\n","            unknown_labels = set(test_df[col].unique()) - set(le.classes_)\n","            if unknown_labels:\n","                le.classes_ = np.append(le.classes_, list(unknown_labels))\n","            test_df[col] = le.transform(test_df[col])\n","\n","# Preparar dados para treinamento\n","X = train_df.drop(['id', 'class'], axis=1)\n","y = train_df['class']\n","\n","# Definir a função de objetivo para o Optuna\n","def objective(trial):\n","    # Definindo os hiperparâmetros a serem otimizados\n","    param = {\n","        'max_depth': trial.suggest_int('max_depth', 3, 9),\n","        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'logloss',\n","        'use_label_encoder': False\n","    }\n","\n","    model = xgb.XGBClassifier(**param, random_state=42)\n","\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Ajustar o modelo\n","    model.fit(X_train, y_train)\n","\n","    # Prever e calcular o MCC\n","    y_pred = model.predict(X_val)\n","    mcc = matthews_corrcoef(y_val, y_pred)\n","\n","    return mcc\n","\n","# Criar e otimizar o estudo com Optuna\n","study = optuna.create_study(direction='maximize')  # Maximizar o MCC\n","study.optimize(objective, n_trials=50)  # Número de combinações a serem testadas\n","\n","# Resultados\n","print('Melhores hiperparâmetros: ', study.best_params)\n","print('Melhor MCC: ', study.best_value)\n"]},{"cell_type":"markdown","metadata":{"id":"p8rbH6fU3Lok"},"source":["Melhores hiperparâmetros:  {'max_depth': 9, 'subsample': 0.9276592101046933, 'colsample_bytree': 0.9119456082162385}  \n","Melhor MCC:  0.9837397566419347"]},{"cell_type":"markdown","source":["**Testando o melhor hiperparametro achado**"],"metadata":{"id":"XPzt8Tznkh66"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45045,"status":"ok","timestamp":1725820142821,"user":{"displayName":"Pedro Gabriel Barruetavena Vieira","userId":"05781803319001527728"},"user_tz":180},"id":"qt7RV1Yy49ZQ","outputId":"ee1bb7c1-1b37-47d2-aa6f-7cca06000075"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/MyDrive/rdc/tei\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/rdc/tei\n","\n","import pandas as pd\n","import numpy as np  # Importar numpy para manipulação de arrays\n","import xgboost as xgb\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Carregar os dados\n","train_df = pd.read_csv('train.csv')\n","test_df = pd.read_csv('test.csv')\n","\n","# Criar LabelEncoders para cada coluna categórica\n","label_encoders = {}\n","\n","# Transformação no conjunto de treino\n","for col in train_df.columns:\n","    if col != 'id':  # Não transformamos a coluna 'id'\n","        le = LabelEncoder()\n","        train_df[col] = le.fit_transform(train_df[col])\n","        label_encoders[col] = le  # Armazenar o encoder para usar no teste\n","\n","# Transformação no conjunto de teste\n","for col in test_df.columns:\n","    if col != 'id':  # Não transformamos a coluna 'id'\n","        le = label_encoders.get(col)  # Recuperar o encoder correspondente\n","        if le is not None:\n","            # Identificar e tratar rótulos desconhecidos\n","            unknown_labels = set(test_df[col].unique()) - set(le.classes_)\n","            if unknown_labels:\n","                le.classes_ = np.append(le.classes_, list(unknown_labels))\n","            test_df[col] = le.transform(test_df[col])\n","\n","# Preparar dados para treinamento\n","X = train_df.drop(['id', 'class'], axis=1)\n","y = train_df['class']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":57075,"status":"ok","timestamp":1725820204461,"user":{"displayName":"Pedro Gabriel Barruetavena Vieira","userId":"05781803319001527728"},"user_tz":180},"id":"sdutvAZ-3X1s","outputId":"0c1a4f66-894f-4497-f11a-c687296ee1f8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:29:15] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.9119456082162385, device=None,\n","              early_stopping_rounds=None, enable_categorical=False,\n","              eval_metric=&#x27;logloss&#x27;, feature_types=None, gamma=None,\n","              grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=9, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=100, n_jobs=None,\n","              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.9119456082162385, device=None,\n","              early_stopping_rounds=None, enable_categorical=False,\n","              eval_metric=&#x27;logloss&#x27;, feature_types=None, gamma=None,\n","              grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=9, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=100, n_jobs=None,\n","              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"],"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.9119456082162385, device=None,\n","              early_stopping_rounds=None, enable_categorical=False,\n","              eval_metric='logloss', feature_types=None, gamma=None,\n","              grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=9, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=100, n_jobs=None,\n","              num_parallel_tree=None, random_state=42, ...)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["best_params = {\n","    'max_depth': 9,\n","    'subsample': 0.9276592101046933,\n","    'colsample_bytree': 0.9119456082162385,\n","    'learning_rate': 0.1,\n","    'n_estimators': 100,\n","    'objective': 'binary:logistic',\n","    'eval_metric': 'logloss',\n","    'use_label_encoder': False,\n","    'random_state': 42\n","}\n","\n","model = xgb.XGBClassifier(**best_params)\n","model.fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBsK2ylb4FtL"},"outputs":[],"source":["test_predictions = model.predict(test_df.drop('id', axis=1))\n"]},{"cell_type":"markdown","metadata":{"id":"0czvZVXA8TBn"},"source":["**Score Kaggle: 0.98236**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLPUSE7m6ID2"},"outputs":[],"source":["test_df['class'] = test_predictions\n","test_df['class'].replace({0: 'e', 1: 'p'}, inplace=True)\n","test_df[[\"id\",\"class\"]].to_csv(\"p_col.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Dsg89dljh2VJ","outputId":"89f2e577-2056-4bd4-9125-2fe57fac51f7"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-09-08 18:18:01,202] A new study created in memory with name: no-name-1e7e7289-7f69-4c73-9a85-49a1b7d8f514\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:18:10] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:18:46,514] Trial 0 finished with value: 0.983025190756654 and parameters: {'max_depth': 7, 'subsample': 0.7368740958366682, 'colsample_bytree': 0.8223889157361134}. Best is trial 0 with value: 0.983025190756654.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:18:53] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:19:31,378] Trial 1 finished with value: 0.9833160015663082 and parameters: {'max_depth': 8, 'subsample': 0.7882948127569208, 'colsample_bytree': 0.9055085905606409}. Best is trial 1 with value: 0.9833160015663082.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:19:38] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:19:56,603] Trial 2 finished with value: 0.9490229276275258 and parameters: {'max_depth': 3, 'subsample': 0.754311846750019, 'colsample_bytree': 0.8834433316512547}. Best is trial 1 with value: 0.9833160015663082.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:20:03] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:20:43,569] Trial 3 finished with value: 0.983593473167851 and parameters: {'max_depth': 9, 'subsample': 0.9011739923790979, 'colsample_bytree': 0.8376602700524115}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:20:49] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:21:32,286] Trial 4 finished with value: 0.9833933062457868 and parameters: {'max_depth': 9, 'subsample': 0.7871797699798316, 'colsample_bytree': 0.8952284291380119}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:21:41] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:22:19,543] Trial 5 finished with value: 0.9832555128848377 and parameters: {'max_depth': 7, 'subsample': 0.7466597945920401, 'colsample_bytree': 0.7926282888087732}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:22:28] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:23:02,111] Trial 6 finished with value: 0.982498713011749 and parameters: {'max_depth': 6, 'subsample': 0.9417929238947562, 'colsample_bytree': 0.9485342991929682}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:23:10] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:23:54,049] Trial 7 finished with value: 0.9833968270025444 and parameters: {'max_depth': 8, 'subsample': 0.9040528170821013, 'colsample_bytree': 0.703865370186074}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:24:01] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:24:56,217] Trial 8 finished with value: 0.9835906190403026 and parameters: {'max_depth': 9, 'subsample': 0.7297534880933197, 'colsample_bytree': 0.8351005260226035}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:25:04] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:25:49,380] Trial 9 finished with value: 0.9834487225422068 and parameters: {'max_depth': 8, 'subsample': 0.853738038329088, 'colsample_bytree': 0.8943786500284894}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:25:58] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:26:21,266] Trial 10 finished with value: 0.9735928869508053 and parameters: {'max_depth': 4, 'subsample': 0.9842474771796251, 'colsample_bytree': 0.7553674920900856}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:26:29] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:27:15,386] Trial 11 finished with value: 0.983525244624942 and parameters: {'max_depth': 9, 'subsample': 0.85546098827981, 'colsample_bytree': 0.9967512025745457}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:27:23] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:27:50,914] Trial 12 finished with value: 0.9801037975405541 and parameters: {'max_depth': 5, 'subsample': 0.8753093551801733, 'colsample_bytree': 0.827701392354586}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:27:58] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:28:41,059] Trial 13 finished with value: 0.9835583677591405 and parameters: {'max_depth': 9, 'subsample': 0.7014881130321453, 'colsample_bytree': 0.764420336871176}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:28:47] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:29:23,122] Trial 14 finished with value: 0.9831741774438898 and parameters: {'max_depth': 7, 'subsample': 0.9212253311814468, 'colsample_bytree': 0.8486747637449941}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:29:29] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:29:58,932] Trial 15 finished with value: 0.9823115775197301 and parameters: {'max_depth': 6, 'subsample': 0.8180923232819474, 'colsample_bytree': 0.7939837634705746}. Best is trial 3 with value: 0.983593473167851.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:30:06] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:30:46,191] Trial 16 finished with value: 0.983690932940172 and parameters: {'max_depth': 9, 'subsample': 0.9717458263739642, 'colsample_bytree': 0.8609762254882399}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:30:53] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:31:28,310] Trial 17 finished with value: 0.9833836312134393 and parameters: {'max_depth': 8, 'subsample': 0.9984689641353995, 'colsample_bytree': 0.9149538477477257}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:31:35] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:32:03,398] Trial 18 finished with value: 0.9798656938452278 and parameters: {'max_depth': 5, 'subsample': 0.9650987293159579, 'colsample_bytree': 0.9490409255170603}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:32:09] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:32:44,341] Trial 19 finished with value: 0.9831381602405205 and parameters: {'max_depth': 7, 'subsample': 0.894115158071093, 'colsample_bytree': 0.852043102274447}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:32:50] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:33:33,831] Trial 20 finished with value: 0.9834994807032232 and parameters: {'max_depth': 9, 'subsample': 0.940116626986392, 'colsample_bytree': 0.8704448473891}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:33:39] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:34:20,530] Trial 21 finished with value: 0.9834477206524862 and parameters: {'max_depth': 9, 'subsample': 0.9648702080416647, 'colsample_bytree': 0.8255221964791074}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:34:28] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:35:04,630] Trial 22 finished with value: 0.9834551026193099 and parameters: {'max_depth': 8, 'subsample': 0.8259230683285586, 'colsample_bytree': 0.7973378684631804}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:35:12] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:35:53,669] Trial 23 finished with value: 0.9836390201361936 and parameters: {'max_depth': 9, 'subsample': 0.9297192559370574, 'colsample_bytree': 0.8640617458519064}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:36:00] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:36:40,208] Trial 24 finished with value: 0.9834323227662702 and parameters: {'max_depth': 8, 'subsample': 0.9370617592365458, 'colsample_bytree': 0.8702577516766735}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:36:46] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:37:27,831] Trial 25 finished with value: 0.9836586589234336 and parameters: {'max_depth': 9, 'subsample': 0.8976039253647168, 'colsample_bytree': 0.9316971972971276}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:37:35] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:38:10,649] Trial 26 finished with value: 0.9834387044054191 and parameters: {'max_depth': 8, 'subsample': 0.9617972337083707, 'colsample_bytree': 0.924224664796778}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:38:17] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:39:01,916] Trial 27 finished with value: 0.9835415212498818 and parameters: {'max_depth': 9, 'subsample': 0.8780559195867311, 'colsample_bytree': 0.9966098916859485}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:39:07] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:39:40,401] Trial 28 finished with value: 0.9830023809904468 and parameters: {'max_depth': 7, 'subsample': 0.9207556973094444, 'colsample_bytree': 0.9399867979981071}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:39:47] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:40:21,627] Trial 29 finished with value: 0.9830286583509805 and parameters: {'max_depth': 7, 'subsample': 0.9810192849611045, 'colsample_bytree': 0.8630406783742054}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:40:29] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:40:53,623] Trial 30 finished with value: 0.980644352680226 and parameters: {'max_depth': 5, 'subsample': 0.9274717590463788, 'colsample_bytree': 0.9279147822841181}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:41:00] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:41:42,084] Trial 31 finished with value: 0.983483677653314 and parameters: {'max_depth': 9, 'subsample': 0.9046977711919937, 'colsample_bytree': 0.8095229413308725}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:41:48] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:42:30,353] Trial 32 finished with value: 0.9835934946660276 and parameters: {'max_depth': 9, 'subsample': 0.8816154118004303, 'colsample_bytree': 0.9792876101221101}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:42:37] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:43:13,693] Trial 33 finished with value: 0.9835004101822059 and parameters: {'max_depth': 8, 'subsample': 0.8763871633037594, 'colsample_bytree': 0.9655534833392063}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:43:21] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:43:39,431] Trial 34 finished with value: 0.9476920538918653 and parameters: {'max_depth': 3, 'subsample': 0.9572814108453966, 'colsample_bytree': 0.9737112659561765}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:43:45] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:44:26,558] Trial 35 finished with value: 0.9835775413785744 and parameters: {'max_depth': 9, 'subsample': 0.8339146171949323, 'colsample_bytree': 0.9629866079669699}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:44:35] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:45:11,837] Trial 36 finished with value: 0.9834125453160226 and parameters: {'max_depth': 8, 'subsample': 0.8870370468269142, 'colsample_bytree': 0.8991869119179083}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:45:18] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:46:00,092] Trial 37 finished with value: 0.9835646843783866 and parameters: {'max_depth': 9, 'subsample': 0.7946964006052583, 'colsample_bytree': 0.9745222931122761}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:46:05] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:46:43,471] Trial 38 finished with value: 0.983345302897131 and parameters: {'max_depth': 8, 'subsample': 0.9116793211213448, 'colsample_bytree': 0.908822626334159}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:46:49] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:47:25,914] Trial 39 finished with value: 0.9823443772678951 and parameters: {'max_depth': 6, 'subsample': 0.8636580864696582, 'colsample_bytree': 0.8771095452033482}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:47:32] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:48:23,865] Trial 40 finished with value: 0.9835808990750217 and parameters: {'max_depth': 9, 'subsample': 0.8404567679165018, 'colsample_bytree': 0.890172084392007}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:30] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:49:13,795] Trial 41 finished with value: 0.9836066571189271 and parameters: {'max_depth': 9, 'subsample': 0.8943129873346661, 'colsample_bytree': 0.8511144708006232}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:49:21] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:50:01,241] Trial 42 finished with value: 0.9835289858774873 and parameters: {'max_depth': 9, 'subsample': 0.9505596176626556, 'colsample_bytree': 0.8542374236718976}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:50:07] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:50:50,222] Trial 43 finished with value: 0.9836485875764693 and parameters: {'max_depth': 9, 'subsample': 0.8980414707985761, 'colsample_bytree': 0.774258287682891}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:50:56] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:51:33,418] Trial 44 finished with value: 0.9834778140501791 and parameters: {'max_depth': 8, 'subsample': 0.9109211584721372, 'colsample_bytree': 0.7672857519951165}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:51:40] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:52:18,884] Trial 45 finished with value: 0.9834933098447288 and parameters: {'max_depth': 9, 'subsample': 0.9282661745225574, 'colsample_bytree': 0.7348018949391436}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:52:26] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:53:08,265] Trial 46 finished with value: 0.9834512926412896 and parameters: {'max_depth': 9, 'subsample': 0.9789130310114792, 'colsample_bytree': 0.8377435538621185}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:53:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:53:52,465] Trial 47 finished with value: 0.9834289616639906 and parameters: {'max_depth': 8, 'subsample': 0.8920999627941818, 'colsample_bytree': 0.7122632341902131}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:53:58] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:54:38,223] Trial 48 finished with value: 0.9835646401946266 and parameters: {'max_depth': 9, 'subsample': 0.9475187041110139, 'colsample_bytree': 0.818189775858097}. Best is trial 16 with value: 0.983690932940172.\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:54:45] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","[I 2024-09-08 18:55:21,806] Trial 49 finished with value: 0.9834805407592215 and parameters: {'max_depth': 8, 'subsample': 0.8613164739107908, 'colsample_bytree': 0.7746053205497622}. Best is trial 16 with value: 0.983690932940172.\n"]}],"source":["study = optuna.create_study(direction='maximize')  # Maximizar o MCC\n","study.optimize(objective, n_trials=50)  # Número de combinações a serem testadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zC2rwbloh4wZ"},"outputs":[],"source":["print('Melhores hiperparâmetros: ', study.best_params)\n","print('Melhor MCC: ', study.best_value)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}